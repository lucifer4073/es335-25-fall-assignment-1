# Human Activity Recognition using Decision Trees

## Project Overview
This project implements Human Activity Recognition (HAR) using Decision Tree classifiers on the UCI HAR Dataset. Three different feature extraction approaches are compared: raw accelerometer data, TSFEL-generated features, and dataset-provided engineered features.

## Results

### 1. Decision Tree Model Training and Comparison

#### Model 1: Raw Accelerometer Data
A Decision Tree model was trained directly on the raw, flattened accelerometer data (384 features per sample).

- **Accuracy**: 70.58%
- **Precision (weighted avg)**: 70.65%
- **Recall (weighted avg)**: 70.58%
- **Confusion Matrix**: The model was particularly good at identifying LAYING but showed significant confusion between the three dynamic activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS) and between the two similar static activities (SITTING, STANDING). The confusion matrix was saved as `confusion_matrix_raw.png`.

#### Model 2: TSFEL Features
A second model was trained on features generated by the TSFEL library (468 features per sample).

- **Accuracy**: 82.73%
- **Precision (weighted avg)**: 82.98%
- **Recall (weighted avg)**: 82.73%
- **Confusion Matrix**: This model showed a dramatic improvement over the raw data model. The separation between classes is much clearer, especially for dynamic activities. LAYING is still perfectly classified. The confusion matrix was saved as `confusion_matrix_tsfel.png`.

#### Model 3: Dataset-Provided Features
The third model was trained on the 561 pre-engineered features provided by the dataset's authors.

- **Accuracy**: 86.26%
- **Precision (weighted avg)**: 86.36%
- **Recall (weighted avg)**: 86.26%
- **Confusion Matrix**: This model achieved the highest performance. It demonstrates the power of expertly crafted features, showing the best class separation and lowest confusion among all three models. The confusion matrix was saved as `confusion_matrix_dataset.png`.

#### Comparison and Conclusion

Based on the results, the model trained on the dataset-provided features is definitively the best, achieving the highest accuracy, precision, and recall.

| Model Type | Accuracy | Precision | Recall |
|------------|----------|-----------|---------|
| Raw Data | 70.58% | 70.65% | 70.58% |
| TSFEL Features | 82.73% | 82.98% | 82.73% |
| Dataset Features | 86.26% | 86.36% | 86.26% |

This comparison clearly demonstrates the critical importance of feature engineering. Moving from raw data to automatically generated TSFEL features provided a massive ~12% accuracy boost. The expertly engineered features from the dataset authors provided an additional ~4% boost, confirming that high-quality features are the most crucial element for this classification task.

### 2. Decision Tree Depth Analysis

Decision Tree models were trained with varying depths from 2 to 8 for all three feature sets. The accuracy on the test data was plotted against the tree depth, and the resulting graph was saved as `depth_analysis.png`.

The optimal depths and corresponding accuracies for each model were:

- **Raw Data Model**: Achieved its best accuracy of 73.60% at a depth of 8.
- **TSFEL Features Model**: Achieved its best accuracy of 84.63% at a depth of 7.
- **Dataset Features Model**: Achieved its best accuracy of 86.87% at a depth of 8.

The plot shows that for all models, accuracy generally increases with tree depth. However, the models with engineered features (TSFEL, dataset) consistently outperform the raw data model at every depth level. The TSFEL model's performance peaking at depth 7 suggests that a more complex tree does not necessarily lead to better generalization for that feature set.

### 3. Analysis of Participants and Activities with Poor Performance

#### Activities with Poor Performance

Even in the best model (using dataset features), some activities were harder to classify than others.

The two worst-performing activities were:

1. **SITTING** (76.37% recall)
2. **WALKING_UPSTAIRS** (78.34% recall)

**Why these activities perform poorly:**

The model has the most trouble distinguishing between **SITTING** and **STANDING**. This is a classic challenge in HAR because both are static activities where the user is upright. From a waist-mounted accelerometer, the signals are extremely similar, leading to high confusion between them.

Similarly, while the dynamic activities are better classified with good features, the model still sometimes confuses **WALKING_UPSTAIRS** with **WALKING** and **WALKING_DOWNSTAIRS**. All three share the same fundamental periodic pattern of stepping. The differences in the signal due to changes in incline are subtle, making them harder to separate perfectly compared to telling the difference between a dynamic activity (like walking) and a static one (like laying down).

#### Participant-Level Performance Analysis

While our current analysis focuses on overall model performance, participant-specific variations likely exist due to:

**Individual Differences:**
- **Movement patterns**: Each person has unique gait characteristics, step frequency, and movement style
- **Device positioning**: Slight variations in smartphone placement (pocket, belt, bag) affect accelerometer readings
- **Anthropometric factors**: Height, weight, and body composition influence movement signatures

**Demographic Variations:**
- **Age-related differences**: Older participants may have different movement patterns affecting classification accuracy
- **Fitness levels**: Athletic vs. sedentary individuals may show distinct activity signatures
- **Physical limitations**: Any mobility constraints could impact signal patterns

**Note**: A complete participant-level analysis would require grouping results by the subject IDs provided in the original dataset files (`subject_train.txt` and `subject_test.txt`) to identify which specific participants show consistently lower classification accuracy across activities.

## Files Generated

- `confusion_matrix_raw.png` - Confusion matrix for raw data model
- `confusion_matrix_tsfel.png` - Confusion matrix for TSFEL features model
- `confusion_matrix_dataset.png` - Confusion matrix for dataset features model
- `depth_analysis.png` - Accuracy vs tree depth comparison plot

## Key Findings

1. **Feature engineering is crucial** for HAR performance
2. **TSFEL provides significant improvement** over raw data with minimal effort
3. **Expert-crafted features** still outperform automated feature extraction
4. **Deeper trees generally perform better** but optimal depth varies by feature type
5. **Static activity discrimination** remains the primary challenge in HAR
